
# ğŸ§  RAG-Based Semantic Quote Retrieval and Structured QA

> Retrieval-Augmented Generation for semantic search & answer generation using fine-tuned models on quotes.

---

## ğŸ“Œ Project Overview

This project implements a **semantic quote retrieval system** using **Retrieval-Augmented Generation (RAG)**. The system is built on top of a fine-tuned SentenceTransformer model trained on a curated dataset of quotes, and uses a RAG pipeline (retriever + OpenAI generator) to respond to natural language queries with relevant quotes and structured answers.

> âœ… Fine-tuned model  
> âœ… FAISS vector index  
> âœ… RAG pipeline  
> âœ… RAGAS evaluation  
> âœ… Interactive Streamlit app

---

## ğŸ¯ Objective

To build a system that:
- Retrieves **semantically relevant quotes** based on natural queries
- Leverages **generative models** to create a concise, informative answer
- Evaluates the quality of retrieval + generation using **RAGAS**
- Deploys a **Streamlit UI** for real-time interaction

---

## ğŸ“‚ Project Structure

```bash
rag-quote-search/
â”œâ”€â”€ cleaned_quotes.csv              # Preprocessed dataset
â”œâ”€â”€ fine_tuned_quote_model/        # Saved SentenceTransformer model
â”œâ”€â”€ rag_pipeline_quotes.ipynb      # Notebook for retrieval, RAG, evaluation
â”œâ”€â”€ rag_pipeline_quotes.ipynb      # Notebook for training, indexing, 
â”œâ”€â”€ app.py                         # Streamlit app for user interaction
â”œâ”€â”€ README.md                      # Project overview and instructions
â”œâ”€â”€ evaluation_notes.md            # Evaluation metrics & analysis
```

---

## ğŸš€ How to Run the Project

### ğŸ§± 1. Environment Setup

Install dependencies:
```bash
pip install -r requirements.txt
```

Or manually:
```bash
pip install streamlit faiss-cpu openai pandas sentence-transformers ragas datasets evaluate
```

> âœ… Set your OpenAI key:
```bash
export OPENAI_API_KEY="your-key-here"  # or use .env file
```

---

### ğŸ“˜ 2. Run Jupyter Notebook
```bash
jupyter notebook model_training.ipynb
jupyter notebook rag_pipeline_quotes.ipynb
```
This file covers:
- Loading & cleaning the dataset
- Fine-tuning the model with contrastive loss
- Building FAISS index
- Implementing RAG with OpenAI GPT
- Evaluating with RAGAS

---

### ğŸŒ 3. Launch the Streamlit App
```bash
streamlit run app.py
```
App features:
- Accepts free-form query (e.g., "quotes about courage by women authors")
- Retrieves most relevant quotes
- Generates a coherent response using GPT
- Displays structured output (quote, author, tags, score)

---

## ğŸ§  Model Architecture

- **Base Model**: `sentence-transformers/all-MiniLM-L6-v2`
- **Fine-Tuning Strategy**: `MultipleNegativesRankingLoss`
- **Training Data**: Synthetic queryâ€“quote pairs
- **Indexing**: FAISS (L2 distance, 384D vectors)
- **Generator**: `gpt-4o-mini` via OpenAI API

---

## ğŸ“Š Evaluation (via RAGAS)

| Metric              | Score    |
|---------------------|----------|
| **Faithfulness**     | `1.000`  |
| **Answer Relevancy** | `0.965`  |
| **Context Precision**| `0.250`  |
| **Context Recall**   | `1.000`  |

ğŸ“Œ Interpretation:
- High **faithfulness** â†’ answers are grounded in retrieved quotes  
- High **recall** but lower **precision** â†’ too many quotes retrieved, not all useful  
- Suggests tuning top_k retrieval or adding metadata filters

---

## ğŸ§ª Sample Query

**Input**:
```
quotes about resilience by women authors
```

**Output**:
```json
{
  "quotes": [
    {
      "quote": "You may encounter many defeats, but you must not be defeated.",
      "author": "Maya Angelou",
      "tags": "resilience, women, inspiration",
      "score": 0.83
    },
    ...
  ],
  "generated_answer": "These quotes by inspiring women like Maya Angelou emphasize how resilience is forged through adversity. They reflect determination and inner strength."
}
```

---

## âœ… Design Decisions

- **Contrastive training** for domain-specific semantic retrieval
- **Structured context format** sent to LLM ensures grounded, interpretable generation
- **RAGAS** used for robust, explainable metric-based evaluation
- **Streamlit UI** makes the solution deployable and user-friendly

---

## âš ï¸ Challenges & Learnings

- Synthetic data quality strongly influences retrieval performance  
- Retrieval metrics (precision vs recall) can mislead â€” human inspection still key  
- Prompt engineering matters â€” context formatting helps guide LLM answers  
- RAG systems require careful calibration between **retriever precision** and **generator fluency**

---

## ğŸ›  Future Improvements

- Use LLaMA or Mixtral locally (for cost-free generation)
- Advanced query parsing to apply filters (e.g., â€œonly feminist authorsâ€)
- Cache or pre-generate embeddings to boost speed
- Use `Quotient` or `Arize Phoenix` for deeper evaluations

---

## âœï¸ Authors & Credits

Built by Yashash Gupta as part of a semantic RAG system assignment using Hugging Face, FAISS, OpenAI, and Streamlit.
